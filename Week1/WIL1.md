이번학기 GDSC 인공지능 스터디에 참가했다.
1주차 강의 자료로 공부를 하고, 구글링을 하면서 과제를 풀어봤다.

아예 노베이스로 시작해서 그런지, 강의록에 나오는 대부분의 단어 자체도 아직 낯설고 개념들도 잘 정리되지 않았다.

다시 공부하긴 해야겠지만, 일단 우선 기억하고 가야할 것 같은 것들을 몇개만 정리해보자.

---

### ReLU 함수

![](https://velog.velcdn.com/images/petergbson/post/481cfc4c-0331-494d-871c-9a78f8d1405f/image.png)

원래는 "활성화 함수"로 시그모이드 함수를 사용해서 딥러닝을 수행했다고 한다.
그러나 시그모이드 함수는 레이어를 거칠수록 값이 작아져 기울기 소실(Vanishing gradient) 현상이 발생하는 문제가 있었다.

이 문제를 ReLU 함수가 해결해주었는데, +/- 가 반복되는 신호에서 - 흐름을 차단하는 방식이라고 이해할 수 있다. 
> if x>0 : return x
else : return 0
뭐 대강 이런 식인거같다. 그래서 x<0 인 구간에서는 계속 0이라 - 신호가 차단된다는 의미인 듯.

x>0 인 구간에서는 함수가 특정 값에 수렴하지 않기 때문에 (시그모이드 함수는 1로 수렴한다.) 기울기 소실 문제가 발생하지 않는다.

---

### 파라미터 개수 구하기

![](https://velog.velcdn.com/images/petergbson/post/1f3c62b6-35e9-40a1-89e6-998213b0e69e/image.png)

파라미터 수는 "커널 크기 x 인풋 채널 x 아웃풋 채널"으로 계산한다.
예를 들어 위 사진에서는,
커널 : 3 X 3
인풋 채널 : 128
아웃풋 채널 : 64
이므로 총 파라미터 수는 3 X 3 X 128 X 64 = 73,728이 된다.

---

### 참고
https://gooopy.tistory.com/55 - 렐루 함수
https://oh2279.tistory.com/61 - 파라미터 수 계산
